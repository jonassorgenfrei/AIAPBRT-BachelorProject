x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.10, random_state=0)
print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)

# define the model
model = Sequential()

#hid layer-1
model.add(Dense(200, activation='relu', input_dim=10, kernel_regularizer=l2(0.01)))
model.add(Dropout(0.3, noise_shape=None, seed=None))

#hid layer-2
model.add(Dense(150, activation='relu', kernel_regularizer=l2(0.01)))
model.add(Dropout(0.3, noise_shape=None, seed=None))

#hid layer-3
model.add(Dense(150, activation='softmax', kernel_regularizer=l2(0.01)))
model.add(Dropout(0.3, noise_shape=None, seed=None))

# Output layer
model.add(Dense(1,activation='sigmoid'))	# since the labels to predict are either 0 or 1

opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)
model.compile(loss='binary_crossentropy',optimizer=opt, metrics=['accuracy'])	# using negative log los and adam
print(model.summary())

# Train the Model
model_output = model.fit(x_train, y_train, epochs=100,batch_size=50, verbose=1, validation_data=(x_test, y_test),)